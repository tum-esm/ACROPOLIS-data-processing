{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import plotly.express as px\n",
    "\n",
    "quickflow_directory = \"/Users/patrickaigner/Documents/PROJECTS/ACROPOLIS/Software/quickflow/acropolis/\"\n",
    "local_path = \"../data/\"\n",
    "picarro_path = \"/Users/patrickaigner/Documents/PROJECTS/ACROPOLIS/Database/PICARRO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download to local db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download from hermes database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Pivot on local db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform pivot on downloaded hermes database\n",
    "# TODO: perform the pivot during the download to safe memory space\n",
    "\n",
    "df_parq = pl.scan_parquet(os.path.join(quickflow_directory, \"measurements.parquet\")).collect().pivot(\n",
    "                values=\"value\",\n",
    "                index=[\n",
    "                    \"system_name\",\n",
    "                    \"revision\",\n",
    "                    \"creation_timestamp\",\n",
    "                    \"receipt_timestamp\",\n",
    "                ],\n",
    "                columns=\"attribute\",\n",
    "                aggregate_function=\"first\",\n",
    "            )\n",
    "\n",
    "df_parq.write_parquet(\n",
    "            os.path.join(local_path, \"pivot_measurements.parquet\"),\n",
    "            statistics=True,\n",
    "        )\n",
    "\n",
    "df_parq = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Calibration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join old and new dv\n",
    "\n",
    "df_new = pl.scan_parquet(os.path.join(local_path, \"pivot_measurements.parquet\"))\n",
    "# old db was preprocessed and transformed to match the columns of the pivot(new_db)\n",
    "df_old = pl.scan_parquet(os.path.join(local_path, \"old_db_renamed_measurements.parquet\"))\n",
    "\n",
    "df_new = df_new.select([\"creation_timestamp\",\"system_name\", \"cal_gmp343_filtered\", \"cal_bottle_id\",]) \\\n",
    ".with_columns(pl.col(\"creation_timestamp\").dt.cast_time_unit(\"us\"))\n",
    "df_old = df_old.select([\"creation_timestamp\",\"system_name\", \"cal_gmp343_filtered\", \"cal_bottle_id\",]) \\\n",
    ".with_columns(pl.col(\"creation_timestamp\").dt.cast_time_unit(\"us\"))\n",
    "\n",
    "df = pl.concat([df_new, df_old]).sort(\"creation_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split calibration readings into calibration bottles\n",
    "# currently the split is performed by CO2 concentration as 400 and 800ppm is far apart\n",
    "# TODO: think about splitting by bottle id\n",
    "\n",
    "df = df.with_columns([pl.when(pl.col(\"cal_gmp343_filtered\") < 600).then(pl.col(\"cal_gmp343_filtered\")).otherwise(None).alias(\"cal_400\"),\n",
    "    pl.when(pl.col(\"cal_gmp343_filtered\") > 600).then(pl.col(\"cal_gmp343_filtered\")).otherwise(None).alias(\"cal_800\"),\n",
    "    pl.when(pl.col(\"cal_gmp343_filtered\") < 600).then(pl.col(\"cal_bottle_id\")).otherwise(None).alias(\"cal_bottle_id_400\"),\n",
    "    pl.when(pl.col(\"cal_gmp343_filtered\") > 600).then(pl.col(\"cal_bottle_id\")).otherwise(None).alias(\"cal_bottle_id_800\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by day\n",
    "\n",
    "# group calibration data by day and add back bottle id for later processing\n",
    "dfg = df.groupby([pl.col(\"creation_timestamp\").dt.date(), pl.col(\"system_name\")]).agg([pl.col(\"cal_400\").drop_nulls(),\n",
    "    pl.col(\"cal_800\").drop_nulls(),\n",
    "    pl.col(\"cal_bottle_id_400\").drop_nulls().median(),\n",
    "    pl.col(\"cal_bottle_id_800\").drop_nulls().median()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform averaging\n",
    "\n",
    "def average_bottle(data):\n",
    "    data = data.to_list()\n",
    "    #2nd bottle\n",
    "    if 50 < len(data) < 70:\n",
    "        x = data[int(len(data)*0.3):int(len(data)*0.95)]\n",
    "        return sum(x) / len(x)\n",
    "    #1st bottle\n",
    "    elif 70 < len(data) < 130:\n",
    "        x = data[int(len(data)*0.5):int(len(data)*0.95)]\n",
    "        return sum(x) / len(x)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "dfg = dfg.select([pl.col(\"creation_timestamp\"),\n",
    "    pl.col(\"system_name\"),\n",
    "    pl.col(\"cal_400\").apply(lambda x: average_bottle(x)).alias(\"mean_cal_400\"),\n",
    "    pl.col(\"cal_800\").apply(lambda x: average_bottle(x)).alias(\"mean_cal_800\"),\n",
    "    pl.col(\"cal_bottle_id_400\"),\n",
    "    pl.col(\"cal_bottle_id_800\")\n",
    "    ])\n",
    "\n",
    "dfg.tail().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate slope and intercept\n",
    "\n",
    "# this was preprocessed on recorded lab data\n",
    "df_gas = pl.read_csv(os.path.join(local_path, \"averaged_gases.csv\"))\n",
    "\n",
    "def two_point_calibration(measured_values, true_values):\n",
    "    # Check if input lists have length 2\n",
    "    if len(measured_values) != 2 or len(true_values) != 2:\n",
    "        raise ValueError(\"Both measured_values and true_values must have length 2\")\n",
    "\n",
    "    # Calculate calibration parameters (slope and intercept)\n",
    "    # \n",
    "    slope = (true_values[1] - true_values[0]) / (measured_values[1] - measured_values[0])\n",
    "    # y_true = m * y_meas + t\n",
    "    intercept = true_values[0] - slope * measured_values[0]\n",
    "\n",
    "    return slope, intercept\n",
    "\n",
    "def calc_slope(meas_400, meas_800, id_400, id_800):\n",
    "    if (meas_400 == None) or (meas_800 == None):\n",
    "        return None\n",
    "    \n",
    "    bottles_meas = [meas_400, meas_800]\n",
    "    bottles_true = [df_gas.filter(pl.col(\"Bottle_ID\")== id_400)[\"CO2_dry\"][0],df_gas.filter(pl.col(\"Bottle_ID\")== id_800)[\"CO2_dry\"][0]]\n",
    "\n",
    "    slope, intercept = two_point_calibration(bottles_meas, bottles_true)\n",
    "    \n",
    "    return slope\n",
    "\n",
    "def calc_intercept(meas_400, meas_800, id_400, id_800):\n",
    "    if (meas_400 == None) or (meas_800 == None):\n",
    "        return None\n",
    "    \n",
    "    bottles_meas = [meas_400, meas_800]\n",
    "    bottles_true = [df_gas.filter(pl.col(\"Bottle_ID\")== id_400)[\"CO2_dry\"][0],df_gas.filter(pl.col(\"Bottle_ID\")== id_800)[\"CO2_dry\"][0]]\n",
    "\n",
    "    slope, intercept = two_point_calibration(bottles_meas, bottles_true)\n",
    "    \n",
    "    return intercept\n",
    "\n",
    "# filter for days that have a valid calibration for both bottles\n",
    "dfg = dfg.sort(pl.col(\"creation_timestamp\")) \\\n",
    "    .filter(pl.col(\"mean_cal_400\") > 0.0 ) \\\n",
    "    .filter(pl.col(\"mean_cal_800\") > 0.0 )\n",
    "\n",
    "# calculate slope\n",
    "dfg = dfg.with_columns(pl.struct(['mean_cal_400','mean_cal_800','cal_bottle_id_400','cal_bottle_id_800']) \\\n",
    "    .apply(lambda x: calc_slope(x['mean_cal_400'],x['mean_cal_800'],x['cal_bottle_id_400'],x['cal_bottle_id_800'])) \\\n",
    "    .alias('slope'))\n",
    "\n",
    "# calculate intercept\n",
    "dfg = dfg.with_columns(pl.struct(['mean_cal_400','mean_cal_800','cal_bottle_id_400','cal_bottle_id_800']) \\\n",
    "    .apply(lambda x: calc_intercept(x['mean_cal_400'],x['mean_cal_800'],x['cal_bottle_id_400'],x['cal_bottle_id_800'])) \\\n",
    "    .alias('intercept'))\n",
    "\n",
    "dfg.tail().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe results to parquet\n",
    "\n",
    "dfg.collect().write_parquet(os.path.join(local_path, \"calibration_correction.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise slope and intercept results\n",
    "\n",
    "x = dfg.select(\"creation_timestamp\", \"slope\",\"intercept\",\"system_name\").collect()\n",
    "\n",
    "fig = px.line(x, x=\"creation_timestamp\", y=\"slope\", markers=True, title = \"slope\", color=\"system_name\")\n",
    "fig.show()\n",
    "fig = px.line(x, x=\"creation_timestamp\", y=\"intercept\", markers=True, title = \"intercept\",color=\"system_name\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Picarro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(picarro_path + \"/*/*/*.dat\")\n",
    "\n",
    "# read all *.dat picarro measurement files and add to single db\n",
    "df_list = []\n",
    "for filename in filenames:\n",
    "    df_list.append(pd.read_csv(filename,sep='\\s+'))\n",
    "\n",
    "big_frame = pd.concat(df_list, ignore_index=True)\n",
    "big_frame[\"datetime\"] = pd.to_datetime((big_frame['DATE'] + ' ' + big_frame['TIME']))\n",
    "big_frame.sort_values(by='datetime', inplace = True)\n",
    "\n",
    "big_frame.to_parquet(path = f\"{picarro_path}/picarro.parquet\")\n",
    "big_frame.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
