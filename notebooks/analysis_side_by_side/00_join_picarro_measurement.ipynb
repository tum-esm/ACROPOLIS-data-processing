{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIRECTORY = os.environ.get(\"DATA_DIRECTORY\")\n",
    "PICARRO_DATA_DIRECTORY = os.environ.get(\"PICARRO_DATA_DIRECTORY\")\n",
    "\n",
    "sensor_id = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "# customize pipeline\n",
    "merge_picarro_files = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1h = pl.read_parquet(os.path.join(DATA_DIRECTORY,\"processed\", \"1h_cal_corr_acropolis.parquet\"))\n",
    "\n",
    "if not merge_picarro_files:\n",
    "    df_p_1h = pl.read_parquet(os.path.join(DATA_DIRECTORY,\"processed\", \"1h_cal_corr_picarro.parquet\"))\n",
    "else:\n",
    "    filenames = glob.glob(PICARRO_DATA_DIRECTORY + \"/*/*/*.dat\")\n",
    "\n",
    "    \n",
    "    # read all *.dat picarro measurement files and add to single db\n",
    "    df_list = []\n",
    "    for filename in filenames:\n",
    "        df_list.append(pd.read_csv(filename,sep='\\s+'))\n",
    "\n",
    "    #PANDAS DF\n",
    "    df_p_files = pd.concat(df_list, ignore_index=True)\n",
    "    df_p_files[\"datetime\"] = pd.to_datetime((df_p_files['DATE'] + ' ' + df_p_files['TIME']))\n",
    "    df_p_files.sort_values(by='datetime', inplace = True)\n",
    "    df_p_files.EtalonTemp = pd.to_numeric(df_p_files.EtalonTemp, errors='coerce').fillna(0).astype(np.float64)\n",
    "\n",
    "    df_p_files.to_parquet(path = os.path.join(DATA_DIRECTORY, \"input\", \"picarro.parquet\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_files.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibration\n",
    "\n",
    "# TODO: Add ability for multiple calibration dates\n",
    "# before 23.10\n",
    "# picarro_slope = 1.0061589132696314\n",
    "# picarro_intercept = 0.14607153970888476\n",
    "\n",
    "# after 23.10\n",
    "#picarro_slope = 1.0063874771746113\n",
    "#picarro_intercept = 0.06621464961165202\n",
    "\n",
    "    \n",
    "#after 18.12\n",
    "#picarro_slope = 1.0060713120261249\n",
    "#picarro_intercept = 0.08088569875155827\n",
    "\n",
    "#after 04.09.2024\n",
    "picarro_slope = 1.0071596423631022\n",
    "picarro_intercept = -0.0294852592592747\n",
    "\n",
    "#POLARS DF\n",
    "#1m averaged corrected Picarro dataset\n",
    "df_p_1m = pl.scan_parquet(os.path.join(DATA_DIRECTORY,\"input\", \"picarro.parquet\")) \\\n",
    "    .with_columns(pl.col(\"datetime\").dt.cast_time_unit(\"us\").dt.replace_time_zone(\"UTC\").alias(\"creation_timestamp\")) \\\n",
    "    .sort(\"creation_timestamp\") \\\n",
    "    .with_columns((pl.col(\"CO2_dry\") * picarro_slope + picarro_intercept).alias(\"picarro_corrected\")) \\\n",
    "    .group_by_dynamic(\"creation_timestamp\", every='1m') \\\n",
    "    .agg(pl.all().exclude(\"creation_timestamp\").mean()).collect() \\\n",
    "    .select([\"creation_timestamp\", \"picarro_corrected\", \"h2o_reported\", \"CavityPressure\", \"CavityTemp\"]) \\\n",
    "    .with_columns(pl.lit(\"Picarro\").alias(\"sys_name_short\"),\n",
    "        pl.lit(0.0).alias(\"diff\")) \n",
    "\n",
    "df_p_1m.write_parquet(os.path.join(DATA_DIRECTORY,\"processed\", \"1m_cal_corr_picarro.parquet\"))\n",
    "\n",
    "#1h averaged corrected Picarro dataset\n",
    "df_p_10m = df_p_1m.sort(\"creation_timestamp\") \\\n",
    "    .group_by_dynamic(\"creation_timestamp\", every='10m', by=[\"sys_name_short\"]) \\\n",
    "    .agg(pl.all().exclude(\"creation_timestamp\").mean())\n",
    "    \n",
    "df_p_10m.write_parquet(os.path.join(DATA_DIRECTORY,\"processed\", \"10m_cal_corr_picarro.parquet\"))\n",
    "\n",
    "#1h averaged corrected Picarro dataset\n",
    "df_p_1h = df_p_1m.sort(\"creation_timestamp\") \\\n",
    "    .group_by_dynamic(\"creation_timestamp\", every='1h', by=[\"sys_name_short\"]) \\\n",
    "    .agg(pl.all().exclude(\"creation_timestamp\").mean())\n",
    "    \n",
    "df_p_1h.write_parquet(os.path.join(DATA_DIRECTORY,\"processed\", \"1h_cal_corr_picarro.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_p_1h, x=\"creation_timestamp\", y = \"picarro_corrected\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1h = df_1h.join(df_p_1h.select(\"creation_timestamp\", \"picarro_corrected\"), on = [\"creation_timestamp\"], how= \"left\") \\\n",
    "    .with_columns(diff = pl.col(\"gmp343_corrected\") - pl.col(\"picarro_corrected\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1h.write_parquet(os.path.join(DATA_DIRECTORY, \"processed\", \"1h_acropolis_with_picarro.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_1h.filter(pl.col(\"system_id\") == 2), x=\"creation_timestamp\", y = \"diff\")\n",
    "fig.update_layout(yaxis_range=[-20,20])\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter(df_1h.filter(pl.col(\"system_id\") == 2), x=\"creation_timestamp\", y = \"gmp343_temperature\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
